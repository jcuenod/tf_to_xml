{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tutorial - Using XML Tools on ETCBC Hebrew Data\n",
    "\n",
    "None of what follows would have been possible without:\n",
    "1. The work of ETCBC whose data you can find at https://github.com/ETCBC/bhsa/ and\n",
    "2. The example set by Jonathan Robie with the NT at https://github.com/biblicalhumanities/greek-new-testament/blob/master/labnotes/lxml-tutorial.ipynb\n",
    "\n",
    "To begin to do something analogous with the ETCBC's data, it needed to be converted to an xml tree structure. This xml is available at https://github.com/jcuenod/tf_to_xml/tree/master/output in separate files but `root.xml` contains the whole OT. To see how I generated this data, see the other notebook https://github.com/jcuenod/tf_to_xml/blob/master/convert_tf_bhs_to_xml.ipynb\n",
    "\n",
    "## Importing XML data\n",
    "\n",
    "We're going to use `etree` which is part of the `lxml` package to import and parse our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "tree = etree.parse(\"./output/root.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported it, we can check to see whether all the books are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = tree.xpath('/base/book')\n",
    "len(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, maybe we should list the books just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen\n",
      "Exod\n",
      "Lev\n",
      "Num\n",
      "Deut\n",
      "Josh\n",
      "Judg\n",
      "1Sam\n",
      "2Sam\n",
      "1Kgs\n",
      "2Kgs\n",
      "Isa\n",
      "Jer\n",
      "Ezek\n",
      "Hos\n",
      "Joel\n",
      "Amos\n",
      "Obad\n",
      "Jonah\n",
      "Mic\n",
      "Nah\n",
      "Hab\n",
      "Zeph\n",
      "Hag\n",
      "Zech\n",
      "Mal\n",
      "Ps\n",
      "Job\n",
      "Prov\n",
      "Ruth\n",
      "Song\n",
      "Eccl\n",
      "Lam\n",
      "Dan\n",
      "Ezra\n",
      "Neh\n",
      "Esth\n",
      "1Chr\n",
      "2Chr\n"
     ]
    }
   ],
   "source": [
    "for book in books:\n",
    "    print(book.get(\"id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sucess!\n",
    "\n",
    "# Sentences, Clauses and Phrases\n",
    "\n",
    "Now lets find textual units like sentences. To do so, let's first take note of the structure of the xml:\n",
    "\n",
    "```xml\n",
    "<book id=\"Gen\">\n",
    "    <sentence n=\"1172209\">\n",
    "      <milestone unit=\"verse\" id=\"Gen.1.1\">Gen.1.1</milestone>\n",
    "      <p>בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ </p>\n",
    "      <wg n=\"427553\" level=\"clause\" class=\"x-qatal-X clause\">\n",
    "        <wg n=\"651503\" level=\"phrase\" class=\"Prepositional phrase\">\n",
    "          <w n=\"1\" lemma=\"בְּ\" partOfSpeech=\"prep\" gloss=\"in\">בְּ</w>\n",
    "          <w n=\"2\" lemma=\"רֵאשִׁית\" partOfSpeech=\"subs\" number=\"sg\" gender=\"f\" state=\"a\" gloss=\"beginning\">רֵאשִׁ֖ית</w>\n",
    "        ...\n",
    "```\n",
    "\n",
    "A few features worth noting include:\n",
    "- A milestone occurs at the beginning of every sentence. This means that sometimes there is more than one milestone that refers to a single verse because some verses contain more than one sentence.\n",
    "- A milestone occurs at the beginning of every verse. This means that sometimes there is more than one verse milestone within a single sentence because some sentences span more than one verse.\n",
    "- `<wg>` elements mark both clauses and phrases. This is because I am following the structure I saw in Jonathan Robie's sample data but clauses always contain at least one phrase just as sentences always contain at least one clause.\n",
    "\n",
    "Let's search for all sentences in our tree use the \"`//`\" find anywhere syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = tree.xpath('//sentence')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now what about clauses and phrases. They both use `<wg>` elements and although their roles could distinguish them, we can also use their hierarchy or the `level` attribute to find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clauses = tree.xpath('//sentence/wg') # same as '//wg[@level=\"clause\"]'\n",
    "len(clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253187"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = tree.xpath('//sentence/wg/wg') # same as '//wg[@level=\"phrase\"]'\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've have the hierarchy we can traverse it. But what about finding verses? The problem is that they don't map perfectly to sentences or clauses. They are marked by `<milestone>` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65191"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verses = tree.xpath('//milestone')\n",
    "len(verses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hang on... sometimes these milestones have the same value. Look at the sentences that make up Deut 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "וַיִּקְרָ֣א מֹשֶׁה֮ אֶל־כָּל־יִשְׂרָאֵל֒ \n",
      "וַיֹּ֣אמֶר אֲלֵהֶ֗ם \n",
      "שְׁמַ֤ע יִשְׂרָאֵל֙ אֶת־הַחֻקִּ֣ים וְאֶת־הַמִּשְׁפָּטִ֔ים אֲשֶׁ֧ר אָנֹכִ֛י דֹּבֵ֥ר בְּאָזְנֵיכֶ֖ם הַיֹּ֑ום \n",
      "וּלְמַדְתֶּ֣ם אֹתָ֔ם \n",
      "וּשְׁמַרְתֶּ֖ם לַעֲשֹׂתָֽם׃ \n"
     ]
    }
   ],
   "source": [
    "for sentence in tree.xpath('//sentence[ milestone[@id=\"Deut.5.1\"] ]/p'):\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth paying attention to that query. We are selecting the `<p>` child of any `<sentence>` element that has a `<milestone>` whose `id` attribute matches \"Deut.5.1\".\n",
    "\n",
    "As you can see, Deut 5:1 contains 5 sentences according to the ETCBC data.\n",
    "\n",
    "So to loop back to our question:\n",
    "**How many verses do we *actually* have?**\n",
    "\n",
    "To answer that, lets get get the text from each of our so-called verses (note, the \"text\" is the verse reference; cf. the text of `<milestone>` elements above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_text = list(map(lambda v: v.text, verses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert our `list` of verse references to a `set` because sets only contain unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23208"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_verse_list = set(verse_text)\n",
    "len(unique_verse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's a lot lower than 65191... (but it's accurate)\n",
    "\n",
    "\n",
    "# Finding Textual Units by Features\n",
    "\n",
    "Now that we know how to find verses, sentences, etc.; let's try to find a specific word.\n",
    "\n",
    "Let's begin by looking for all the piel verbs. To find verbs we could just use:\n",
    "\n",
    "```python\n",
    "verbs = tree.xpath('//w[@partOfSpeech=\"verb\"]')\n",
    "```\n",
    "\n",
    "but we know that only verbs occur in the piel so we don't need to worry about the part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piels = tree.xpath('//w[@stem=\"piel\"]')\n",
    "len(piels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other stems are contained in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afel',\n",
       " 'etpa',\n",
       " 'etpe',\n",
       " 'haf',\n",
       " 'hif',\n",
       " 'hit',\n",
       " 'hof',\n",
       " 'hotp',\n",
       " 'hsht',\n",
       " 'htpa',\n",
       " 'htpe',\n",
       " 'htpo',\n",
       " 'nif',\n",
       " 'nit',\n",
       " 'pael',\n",
       " 'pasq',\n",
       " 'peal',\n",
       " 'peil',\n",
       " 'piel',\n",
       " 'poal',\n",
       " 'poel',\n",
       " 'pual',\n",
       " 'qal',\n",
       " 'shaf',\n",
       " 'tif'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll start by finding the verbs\n",
    "verbs = tree.xpath('//w[@partOfSpeech=\"verb\"]')\n",
    "# Then we'll loop through them adding each stem to a set (which only contains unique elements)\n",
    "stem_set = set()\n",
    "for w in verbs:\n",
    "    stem_set.add(w.get(\"stem\"))\n",
    "\n",
    "stem_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a bunch of stems that might not look very familiar to you, that's probably because they're Aramaic stems (this data includes the Aramaic portions of the OT). There are also some stems you may notice seem to be missing like \"Pilpel\" and \"Polal\". ETCBC data parses these words with the \"piel\" stem so those stems will not appear here.\n",
    "\n",
    "What if we want to find a word by more than one feature? Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imperative_piels = tree.xpath('//w[@stem=\"piel\" and @tense=\"impv\"]')\n",
    "len(imperative_piels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a more typical search for a word by its lemma. Let's say we're looking for Moses - in Hebrew, \"מֹשֶׁה\".\n",
    "\n",
    "Unicode data presents us with a problem here. A \"שׁ\" may be represented in two ways, with a `ש + a shin dot` or a pre-composed character. Some of the difficulties that arise may be seen at https://unicode.org/reports/tr15/. Suffice it to say that the xml we are using has used \"NFC\" to normalize the data. To do the same in our search we need the package `unicodedata` and then we simply use the `normalize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "moseses = tree.xpath('//w[@lemma=\"{}\"]'.format(unicodedata.normalize(\"NFC\", \"מֹשֶׁה\")))\n",
    "len(moseses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, it's annoying, but if you use NFC normalized unicode, it won't make much difference to your life. And hey, at least this way your comparisons are not going to fail because even though the words appear identical, the vowel is encoded before the dagesh instead of after it (a problem I have faced before).\n",
    "\n",
    "So if you know your unicode is NFC normalized you can of course just do this (and to figure out the lexemes, it's worth checking the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moseses = tree.xpath('//w[@lemma=\"מֹשֶׁה\"]')\n",
    "len(moseses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how about finding a clause with moses speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moses_amr = tree.xpath('//sentence[ .//w[@lemma=\"מֹשֶׁה\"] and .//w[@lemma=\"אמֶר\"] ]')\n",
    "len(moses_amr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do something more useful with this data than list a number of occurrences, let's look at one more interesting feature in the data set: the clause/phrase relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prepositional phrases: 57464\n",
      "Number of wayyiqtol-x clauses: 5895\n"
     ]
    }
   ],
   "source": [
    "prepositional_phrases = tree.xpath('//wg[@class=\"Prepositional phrase\"]')\n",
    "print(\"Number of prepositional phrases:\", len(prepositional_phrases))\n",
    "\n",
    "wayqx_clauses = tree.xpath('//wg[@class=\"Wayyiqtol-X clause\"]')\n",
    "print(\"Number of wayyiqtol-x clauses:\", len(wayqx_clauses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually print out some of this data we can use something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence with מֹשֶׁה and אמֶר:\n",
      "<sentence n=\"1176997\">\n",
      "      <milestone unit=\"verse\" id=\"Exod.3.3\">Exod.3.3</milestone>\n",
      "      <p>וַיֹּ֣אמֶר מֹשֶׁ֔ה </p>\n",
      "      <wg n=\"433741\" level=\"clause\" class=\"Wayyiqtol-X clause\">\n",
      "        <wg n=\"670067\" level=\"phrase\" class=\"Conjunctive phrase\">\n",
      "          <w n=\"29676\" lemma=\"וַ\" partOfSpeech=\"conj\" gloss=\"and\">וַ</w>\n",
      "        </wg>\n",
      "        <wg n=\"670068\" level=\"phrase\" class=\"Verbal phrase\">\n",
      "          <w n=\"29677\" lemma=\"אמֶר\" partOfSpeech=\"verb\" person=\"3\" number=\"sg\" gender=\"m\" tense=\"wayq\" stem=\"qal\" gloss=\"say\">יֹּ֣אמֶר</w>\n",
      "        </wg>\n",
      "        <wg n=\"670069\" level=\"phrase\" class=\"Proper-noun phrase\">\n",
      "          <w n=\"29678\" lemma=\"מֹשֶׁה\" partOfSpeech=\"nmpr\" number=\"sg\" gender=\"m\" state=\"a\" gloss=\"Moses\">מֹשֶׁ֔ה</w>\n",
      "        </wg>\n",
      "      </wg>\n",
      "    </sentence>\n",
      "    \n",
      "\n",
      "First Wayyiqtol-X clause:\n",
      "<wg n=\"427557\" level=\"clause\" class=\"Wayyiqtol-X clause\">\n",
      "        <wg n=\"651518\" level=\"phrase\" class=\"Conjunctive phrase\">\n",
      "          <w n=\"32\" lemma=\"וַ\" partOfSpeech=\"conj\" gloss=\"and\">וַ</w>\n",
      "        </wg>\n",
      "        <wg n=\"651519\" level=\"phrase\" class=\"Verbal phrase\">\n",
      "          <w n=\"33\" lemma=\"אמֶר\" partOfSpeech=\"verb\" person=\"3\" number=\"sg\" gender=\"m\" tense=\"wayq\" stem=\"qal\" gloss=\"say\">יֹּ֥אמֶר</w>\n",
      "        </wg>\n",
      "        <wg n=\"651520\" level=\"phrase\" class=\"Nominal phrase\">\n",
      "          <w n=\"34\" lemma=\"אֱלֹה\" partOfSpeech=\"subs\" number=\"pl\" gender=\"m\" state=\"a\" gloss=\"god(s)\">אֱלֹהִ֖ים</w>\n",
      "        </wg>\n",
      "      </wg>\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First sentence with מֹשֶׁה and אמֶר:\")\n",
    "print(etree.tostring(moses_amr[0], pretty_print=True, encoding=\"utf-8\").decode(\"utf-8\"))\n",
    "\n",
    "print(\"First Wayyiqtol-X clause:\")\n",
    "print(etree.tostring(wayqx_clauses[0], pretty_print=True, encoding=\"utf-8\").decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our searches the last element in the xpath chain is what was returned `<sentence>` in the first case and `<wg>` in the second. So if we wanted to find out the verse references for these searches we would need to find the associated milestone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exod.3.3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moses_amr[0].xpath(\"./milestone\")[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find it for the `<wg>` element we could edit our previous search to find the parent `<sentence>`. Or, as we have just done, we can use xpath to find the parent (this works because we know that our clause `<wg>` only needs to navigate up one level to hit a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gen.1.3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wayqx_clauses[0].xpath(\"../milestone\")[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Something Cool\n",
    "\n",
    "Well, now that we can find verse references based on our searches, let's try to do something interesting.\n",
    "\n",
    "I glanced at the Moses + Speaking data and noticed that of the 134 values returned, a lot of them seemed to be \"Wayyiqtol-X\" clauses. So let's see where that is *not* the case (it turns out there are only two, so we'll just print them out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exod.18.6       וַיֹּ֨אמֶר֙ אֶל־מֹשֶׁ֔ה \n",
      "Exod.32.17      וַיֹּ֨אמֶר֙ אֶל־מֹשֶׁ֔ה \n"
     ]
    }
   ],
   "source": [
    "moses_amr_not_wayqx = tree.xpath('//sentence[ .//wg[ .//w[@lemma=\"מֹשֶׁה\"] and .//w[@lemma=\"אמֶר\"] and not(@class=\"Wayyiqtol-X clause\") ] ]')\n",
    "\n",
    "for sentence in moses_amr_not_wayqx:\n",
    "    print('{:15}'.format(sentence.xpath(\"./milestone\")[0].text), sentence.xpath(\"./p\")[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
